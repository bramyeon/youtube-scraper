{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bramyeon/youtube-scraper/blob/main/youtube_scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0fbDx2_G4-w"
      },
      "source": [
        "# (Daewoong AI) 09-medical-trend: <b>YouTube Scraper</b>\n",
        "\n",
        "Developed by [Bryan Nathanael Wijaya](mailto:bramyeon@gmail.com)  \n",
        "Contact me for inquiries or bug reports ðŸ™Œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3m1fCyuUG4-0"
      },
      "outputs": [],
      "source": [
        "#@title Setting up prerequisites\n",
        "\n",
        "from google.colab import files\n",
        "from googleapiclient.discovery import build\n",
        "from datetime import datetime, timedelta\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "API_KEY = \"insert your API key here\" #@param {type:\"string\"}\n",
        "youtube = build('youtube', 'v3', developerKey=API_KEY)\n",
        "\n",
        "def get_videos(keyword, weeks=2, min_view_count=100000):\n",
        "    publishedAfter = (datetime.now() - timedelta(weeks=weeks)).isoformat() + \"Z\"\n",
        "\n",
        "    videos = []\n",
        "    next_page_token = None\n",
        "\n",
        "    print(f\"Checking all videos with keyword `{keyword}` published within {weeks} weeks, regardless of view counts...\")\n",
        "    while True:\n",
        "        try:\n",
        "            search_response = youtube.search().list(\n",
        "                q=keyword,\n",
        "                part='snippet',\n",
        "                type='video',\n",
        "                publishedAfter=publishedAfter,\n",
        "                maxResults=50,\n",
        "                pageToken=next_page_token\n",
        "            ).execute()\n",
        "\n",
        "            video_ids = []\n",
        "            for item in search_response['items']:\n",
        "                video_ids.append(item['id']['videoId'])\n",
        "\n",
        "            video_response = youtube.videos().list(\n",
        "                part='snippet,statistics',\n",
        "                id=','.join(video_ids)\n",
        "            ).execute()\n",
        "\n",
        "            for video in tqdm(video_response['items']):\n",
        "                view_count = int(video['statistics'].get('viewCount', 0))\n",
        "                if view_count >= min_view_count:\n",
        "                    video_data = {\n",
        "                        'url': f\"https://www.youtube.com/watch?v={video['id']}\",\n",
        "                        'title': video['snippet']['title'],\n",
        "                        'author': video['snippet']['channelTitle'],\n",
        "                        'view_count': view_count,\n",
        "                        'like_count': int(video['statistics'].get('likeCount', 0)),\n",
        "                        'comment_count': int(video['statistics'].get('commentCount', 0)),\n",
        "                        'description': video['snippet']['description'],\n",
        "                        'upload_date': video['snippet']['publishedAt'],\n",
        "                        'video_id': video['id']\n",
        "                    }\n",
        "                    videos.append(video_data)\n",
        "\n",
        "            next_page_token = search_response.get('nextPageToken')\n",
        "            if not next_page_token:\n",
        "                break\n",
        "        except:\n",
        "            break\n",
        "\n",
        "    return videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "JrioT_CuG4-1"
      },
      "outputs": [],
      "source": [
        "#@title YouTube Scraping\n",
        "\n",
        "keyword = \"diabetes\" #@param {type:\"string\"}\n",
        "published_within_in_weeks = 2 #@param {type:\"integer\"}\n",
        "minimum_view_count = 100000 #@param {type:\"integer\"}\n",
        "save_name = \"scraping.csv\" #@param {type:\"string\"}\n",
        "\n",
        "videos = get_videos(keyword, published_within_in_weeks, minimum_view_count)\n",
        "df = pd.DataFrame(videos)\n",
        "\n",
        "save_name = (save_name + '.csv').replace('.csv.csv', '.csv')\n",
        "print(f\"\\n\\nScraping completed!\\nSaving YouTube scraping results as `{save_name}` and downloading...\")\n",
        "df.to_csv(save_name, index=False)\n",
        "files.download(save_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yEJm5aOMzm0b"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "SE3nv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}